{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AZ_EHaNdx18"
      },
      "source": [
        "#'CROSS-SYNTHESIS' VIA AUTOCODER\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vwzyqugew8k"
      },
      "source": [
        "Open this notebook in [Google Colab](https://colab.research.google.com). You can do this by using the Chrome plugin [Open in Colab](https://chrome.google.com/webstore/detail/open-in-colab/iogfkhleblhcpcekbiedikdehleodpjo),<br>\n",
        "or by downloading it from github and uploading it into colab.<br><br>\n",
        "Make sure to set the runtime type to GPU (Runtime->Change Runtime Type) or training will take<br>an enternity.<br><br>\n",
        "You can run each code section by pressing the play button which shows up when you hover over the<br> two brackets with/without a number on the top left of the codebox.\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yh5isLW9KlD"
      },
      "source": [
        "#1. UPLOAD TWO SOUNDFILES\n",
        "Click on the folder icon on the left to expand the file browser and drag and drop a sound-file there.<br>Then edit the filename below to match the uploaded file. Make sure that the file finishes uploading<br> before continuing. The first one is the modulator and the second the carrier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdYCXKCkEspX"
      },
      "outputs": [],
      "source": [
        "filename_1 = \"modulator.wav\"\n",
        "filename_2 = \"carrier.wav\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HeW8mtOEGgv"
      },
      "source": [
        "#2. SELECT ONE OF THE FOLLOWING TO SET THE TRAINING PARAMETERS\n",
        "Some of these presets may not produce usable models with specific datasets\n",
        "so some patience <br>and experimentation may be needed. More training is not always better and some data-sets may<br> need different (lower) values for regression patience to avoid artifacting.<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEMYA5lGD8mW"
      },
      "outputs": [],
      "source": [
        "# LOW QUALITY - TRAINING TIME ROUGHLY .8x DURATION – GOOD ENOUGH FOR EXPLORATION\n",
        "batch_size = 1024\n",
        "regression_patience = 200\n",
        "learning_rate = .0001\n",
        "min_delta = .00001\n",
        "quality = \"low\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCCsEuFlEAs4"
      },
      "outputs": [],
      "source": [
        "# MEDIUM QUALITY – TRAINING TIME ROUGHLY 3x DURATION – GOOD ENOUGH FOR MOST THINGS\n",
        "batch_size = 512\n",
        "regression_patience = 500\n",
        "learning_rate = .0001\n",
        "min_delta = .00001\n",
        "quality = \"medium\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlv8LCsBEFln"
      },
      "outputs": [],
      "source": [
        "# HIGH QUALITY – TRAINING TIME ROUGHLY 5x DURATION\n",
        "batch_size = 256\n",
        "regression_patience = 1000 \n",
        "learning_rate = .0001\n",
        "min_delta = .00001\n",
        "quality = \"high\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i740qfrW1lIj"
      },
      "outputs": [],
      "source": [
        "# EXTREME QUALITY – TRAINING TAKES A VERY LONG TIME\n",
        "batch_size = 256\n",
        "regression_patience = 10000000\n",
        "learning_rate = .0001\n",
        "min_delta = 0\n",
        "quality = \"extreme\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H001mLLR0PoR"
      },
      "source": [
        "#3. RUN THE CODE\n",
        "Depending on the training settings selected above, this can take anywhere from\n",
        ".5x to 5x or more<br> of the duration of the input file so be patient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jLMxztkc_XH",
        "outputId": "58fd8748-6785-4d0c-80bb-8eb4f3126a52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python_speech_features in /usr/local/lib/python3.7/dist-packages (0.6)\n",
            "  ...ANALYZING 1\n",
            "\n",
            "  ####################################\n",
            "  #   number of samples:   395611\n",
            "  ####################################\n",
            "\n",
            "  ...ANALYZING 2\n",
            "\n",
            "  ####################################\n",
            "  #   number of samples:   3175200\n",
            "  ####################################\n",
            "\n",
            "0.0 674.3337549224135\n",
            "0.0 493.52865883643676\n",
            "(371, 512)\n",
            "(3457, 512)\n",
            "input_shape:  (512,)\n",
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 1000)         513000      ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 8)            8008        ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 8)            8008        ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " z (Lambda)                     (None, 8)            0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 529,016\n",
            "Trainable params: 529,016\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " z_sampling (InputLayer)     [(None, 8)]               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1000)              9000      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 512)               512512    \n",
            "                                                                 \n",
            " dot_1 (Dot)                 (None, 8192)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 521,512\n",
            "Trainable params: 521,512\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"training_decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " z_sampling (InputLayer)     [(None, 8)]               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1000)              9000      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 512)               512512    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 521,512\n",
            "Trainable params: 521,512\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install python_speech_features\n",
        "import librosa\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy.signal import hann\n",
        "from python_speech_features.base import get_filterbanks\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import math\n",
        "import time\n",
        "\n",
        "# ANALYSIS SETTINGS\n",
        "fftsize = 16384\n",
        "windowskip = 1024\n",
        "\n",
        "# MODEL STRUCTURE\n",
        "input_dim = 512\n",
        "intermediate_dim = 1000\n",
        "encoded_dim = 8\n",
        "output_fft_size = 16384\n",
        "\n",
        "def create_mel_filter(fft_size, n_freq_components = 64, start_freq = 300, end_freq = 8000, samplerate = 44100):\n",
        "    filterbanks = get_filterbanks(nfilt=n_freq_components,\n",
        "                                           nfft=fft_size, samplerate=samplerate,\n",
        "                                           lowfreq=start_freq, highfreq=end_freq)\n",
        "    mel_inversion_filter = np.ascontiguousarray((filterbanks.T[0:(int(fft_size/2))]).T)\n",
        "    mel_filter = np.ascontiguousarray(np.divide(mel_inversion_filter.T, mel_inversion_filter.sum(axis=1)))\n",
        "\n",
        "    return mel_filter, mel_inversion_filter\n",
        "\n",
        "\n",
        "def initialize(size, melsize):\n",
        "    window = np.zeros((1, size))\n",
        "    window = np.ascontiguousarray(window)\n",
        "    window[0,] = hann(size)\n",
        "    mel_filter, mel_inversion_filter = create_mel_filter(size, melsize, 0, 22050, 44100)\n",
        "    np.nan_to_num(mel_filter, False, nan = 0.0)\n",
        "    np.nan_to_num(mel_inversion_filter, False, nan = 0.0)\n",
        "    return(mel_filter, mel_inversion_filter, window)\n",
        "\n",
        "\n",
        "def convertToBin(data):\n",
        "    return(np.sqrt(np.add(np.multiply(data.real, data.real), np.multiply(data.imag, data.imag))))\n",
        "\n",
        "\n",
        "def spectrogram_to_mel(spectrogram, filter):\n",
        "    mel_spec = np.transpose(filter).dot(np.transpose(spectrogram))\n",
        "    return mel_spec\n",
        "\n",
        "\n",
        "def get_aminmax(X):\n",
        "    return(np.amin(X), np.amax(X))\n",
        "\n",
        "\n",
        "def scale_array_by_amax(X):\n",
        "    return((X - np.amin(X)) / (np.amax(X) - np.amin(X)))\n",
        "\n",
        "def scale_array(X, minin, maxin):\n",
        "    return((X - minin) / (maxin - minin))\n",
        "\n",
        "def analyze(data, window, mel_filter):\n",
        "    data = np.multiply(data, window)\n",
        "    fftdata = scipy.fft.rfft(data)\n",
        "    ampslize = convertToBin(fftdata)\n",
        "    ampslize = np.ascontiguousarray(ampslize)\n",
        "    phase = np.angle(fftdata)\n",
        "    phase = phase[0,0:int(data.shape[1]/2)]\n",
        "    melslize = spectrogram_to_mel(ampslize[0,0:int(data.shape[1]/2)], mel_filter)\n",
        "    return(melslize, ampslize[0,0:int(data.shape[1]/2)], phase)\n",
        "\n",
        "\n",
        "def analyze_data(data, filename, fftsize, windowskip, melsize, window, mel_filter):\n",
        "\n",
        "    n_slizes = round(len(data)/windowskip)\n",
        "    output = np.zeros((int((n_slizes - 16))+1, melsize))\n",
        "    output = np.ascontiguousarray(output)\n",
        "    fft_output = np.zeros((int((n_slizes - 16))+1, int(fftsize / 2)))\n",
        "    fft_output = np.ascontiguousarray(fft_output)\n",
        "    phase_output = np.zeros((int((n_slizes - 16)) + 1, int(fftsize / 2)))\n",
        "    phase_output = np.ascontiguousarray(phase_output)\n",
        "\n",
        "    in_slize = np.zeros((1, fftsize))\n",
        "    in_slize = np.ascontiguousarray(in_slize)\n",
        "    for i in range(0, (n_slizes - 16)):\n",
        "        in_slize[0] = data[i * windowskip:((i*windowskip) + fftsize)]\n",
        "        output[i,:], fft_output[i,:], phase_output[i,:] = analyze(in_slize, window, mel_filter)\n",
        "\n",
        "    output = np.nan_to_num(output, 0.)\n",
        "    minin, maxin = get_aminmax(output)\n",
        "    return(minin, maxin, output, phase_output)\n",
        "\n",
        "\n",
        "def sampling(args):\n",
        "    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
        "    # Arguments\n",
        "        args (tensor): mean and log of variance of Q(z|X)\n",
        "    # Returns\n",
        "        z (tensor): sampled latent vector\n",
        "    \"\"\"\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = 1e-06\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "def init_autoencoder_shallow(input_dim, intermediate_dim, encoded_dim, learning_rate):\n",
        "\n",
        "    input_shape = (input_dim, )\n",
        "    latent_dim = encoded_dim\n",
        "\n",
        "    print(\"input_shape: \", input_shape)\n",
        "\n",
        "    # VAE model = encoder + decoder\n",
        "    # build encoder model\n",
        "    inputs = tf.keras.Input(shape=input_shape, name='encoder_input')\n",
        "    x = tf.keras.layers.Dense(intermediate_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(10e-5), kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-5))(inputs)\n",
        "\n",
        "    z_mean = tf.keras.layers.Dense(latent_dim, name='z_mean')(x)\n",
        "    z_log_var = tf.keras.layers.Dense(latent_dim, name='z_log_var')(x)\n",
        "\n",
        "    # use reparameterization trick to push the sampling out as input\n",
        "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "    z = tf.keras.layers.Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
        "\n",
        "    # instantiate encoder model\n",
        "    encoder = tf.keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "    encoder.summary()\n",
        "\n",
        "    # build decoder model\n",
        "    latent_inputs = tf.keras.Input(shape=(latent_dim,), name='z_sampling')\n",
        "    x = tf.keras.layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
        "    outputs = tf.keras.layers.Dense(input_dim, activation='sigmoid')(x)\n",
        "\n",
        "    # instantiate decoder model\n",
        "    _,mel_inversion_filter = create_mel_filter(output_fft_size, input_dim, 0, 22050, 44100)\n",
        "    mel = K.expand_dims(tf.constant(mel_inversion_filter), 0)\n",
        "    transformed_outputs = tf.keras.layers.Dot(axes=(1,1)) ([outputs, mel])\n",
        "    decoder = tf.keras.Model(latent_inputs, transformed_outputs, name='decoder')\n",
        "    training_decoder = tf.keras.Model(latent_inputs, outputs, name='training_decoder')\n",
        "    decoder.summary()\n",
        "    training_decoder.summary()\n",
        "    # instantiate VAE model\n",
        "    training_outputs = training_decoder(encoder(inputs)[2])\n",
        "    outputs = decoder(encoder(inputs)[2])\n",
        "\n",
        "\n",
        "    vae = tf.keras.Model(inputs, [training_outputs,outputs], name='vae_mlp')\n",
        "\n",
        "    reconstruction_loss = tf.keras.losses.binary_crossentropy(inputs, training_outputs)\n",
        "\n",
        "    reconstruction_loss *= input_dim\n",
        "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "    kl_loss = K.sum(kl_loss, axis=-1)\n",
        "    kl_loss *= -0.5\n",
        "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "    vae.add_loss(vae_loss)\n",
        "    opt = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "\n",
        "    vae.compile(optimizer=opt)\n",
        "    return(vae, encoder, decoder, training_decoder)\n",
        "\n",
        "\n",
        "def get_minmax(encoder, input):\n",
        "    z_encoded = encoder.predict(input)\n",
        "    z_encoded = np.asarray(z_encoded[0], dtype = np.float32)\n",
        "\n",
        "    min = z_encoded.min(axis = 0)\n",
        "    max = z_encoded.max(axis = 0)\n",
        "    scale_mult = np.subtract(max, min)\n",
        "    scale_subtract = min\n",
        "    return(scale_mult, scale_subtract)\n",
        "\n",
        "history = 0\n",
        "\n",
        "def train(filename, vae, encoder, decoder, training_decoder, input, min_delta, regression_patience = 1, batch_size = 4096, deep = 0):\n",
        "    global history\n",
        "    tf.executing_eagerly()\n",
        "    es = tf.keras.callbacks.EarlyStopping(monitor='loss', mode='min', min_delta=min_delta, patience = regression_patience)\n",
        "    history = vae.fit(input,\n",
        "            batch_size = batch_size,\n",
        "            epochs=50000, verbose = 0, callbacks=[es])\n",
        "\n",
        "    vae.save_weights(filename + \".h5\")\n",
        "    scale_mult, scale_subtract = get_minmax(encoder, input)\n",
        "\n",
        "    converter_enc = tf.lite.TFLiteConverter.from_keras_model(encoder)\n",
        "    converter_dec = tf.lite.TFLiteConverter.from_keras_model(decoder)\n",
        "    converter_training_dec = tf.lite.TFLiteConverter.from_keras_model(training_decoder)\n",
        "    tflite_model_enc = converter_enc.convert()\n",
        "    tflite_model_dec = converter_dec.convert()\n",
        "    tflite_model_training_dec = converter_training_dec.convert()\n",
        "\n",
        "    # Save the models\n",
        "    with open(filename + '.enc', 'wb') as f:\n",
        "      f.write(tflite_model_enc)\n",
        "    with open(filename + '.fft.dec', 'wb') as f:\n",
        "      f.write(tflite_model_dec)\n",
        "    with open(filename + '.dec', 'wb') as f:\n",
        "      f.write(tflite_model_training_dec)\n",
        "\n",
        "    return(vae, encoder, decoder, training_decoder, scale_mult, scale_subtract)\n",
        "\n",
        "\n",
        "def write_mm(filename, minin, maxin, scale_mult, scale_subtract, input_dim, intermediate_dim, encoded_dim, deep):\n",
        "    output_ = np.zeros([3, 8])\n",
        "    output_[0] = scale_mult\n",
        "    output_[1] = scale_subtract\n",
        "    output_[2][0] = minin\n",
        "    output_[2][1] = maxin\n",
        "    output_[2][2] = input_dim\n",
        "    output_[2][3] = intermediate_dim\n",
        "    output_[2][4] = encoded_dim\n",
        "    output_[2][5] = deep\n",
        "    np.savetxt(filename + \".mm\", output_, delimiter = \", \", fmt=\"%1.6f\")\n",
        "  \n",
        "imported_data_1,_ = librosa.load(filename_1, sr = 44100, mono = True)\n",
        "imported_data_2,_ = librosa.load(filename_2, sr = 44100, mono = True)\n",
        "print(\"  ...ANALYZING 1\")\n",
        "print(\"\")\n",
        "print(\"  ####################################\")\n",
        "print(\"  #   number of samples:  \", len(imported_data_1))\n",
        "print(\"  ####################################\")\n",
        "print(\"\")\n",
        "\n",
        "mel_filter, mel_inversion_filter, window = initialize(fftsize, input_dim)\n",
        "minin_1, maxin_1, input_data_1, phase_data_1 = analyze_data(imported_data_1, filename_1, fftsize, windowskip, input_dim, window, mel_filter)\n",
        "print(\"  ...ANALYZING 2\")\n",
        "print(\"\")\n",
        "print(\"  ####################################\")\n",
        "print(\"  #   number of samples:  \", len(imported_data_2))\n",
        "print(\"  ####################################\")\n",
        "print(\"\")\n",
        "minin_2, maxin_2, input_data_2, phase_data_2 = analyze_data(imported_data_2, filename_2, fftsize, windowskip, input_dim, window, mel_filter)\n",
        "print(np.amin(input_data_1), np.amax(input_data_1))\n",
        "print(np.amin(input_data_2), np.amax(input_data_2))\n",
        "print(input_data_1.shape)\n",
        "output = np.append(input_data_1, input_data_2, axis = 0)\n",
        "print(output.shape)\n",
        "output  = np.nan_to_num(output, 0.)\n",
        "minin, maxin = get_aminmax(output)\n",
        "input_data = scale_array(output, minin, maxin)\n",
        "input_data_1 = scale_array(input_data_1, minin, maxin)\n",
        "input_data_2 = scale_array(input_data_2, minin, maxin)\n",
        "\n",
        "vae, encoder, decoder, training_decoder = init_autoencoder_shallow(input_dim, intermediate_dim, encoded_dim, learning_rate)\n",
        "vae, encoder, decoder, training_decoder, scale_mult, scale_subtract = train(filename_1, vae, encoder, decoder, training_decoder, input_data, min_delta, regression_patience, batch_size, 0)\n",
        "\n",
        "# ONCE THEY ARE TRAINED, RUN EACH MODEL THROUGH TO GET THE SCALE_MULT / SCALE_SUBTRACT FOR EACH\n",
        "\n",
        "def get_each_min_max(encoder, input):\n",
        "    z_encoded = encoder.predict(input)\n",
        "    z_encoded = np.asarray(z_encoded[0], dtype = np.float32)\n",
        "\n",
        "    min = z_encoded.min(axis = 0)\n",
        "    max = z_encoded.max(axis = 0)\n",
        "    return(min, max)\n",
        "\n",
        "\n",
        "scale_min_1, scale_max_1 = get_each_min_max(encoder, input_data_1)\n",
        "scale_min_2, scale_max_2 = get_each_min_max(encoder, input_data_2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CROSS SYNTHESIZE\n",
        "This is no way an actual cross synthesis. It simply trains a model on two soundfiles and fits the latent space of the modulator onto the latent space of the carrier, using the phase of the modulator for resynthesis."
      ],
      "metadata": {
        "id": "yh9ETcW6iwr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io.wavfile\n",
        "\n",
        "\n",
        "def apply_one_to_the_other(encoder, decoder, input, min_1, max_1, min_2, max_2):\n",
        "  z_encoded = encoder.predict(input)\n",
        "  z_encoded = np.asarray(z_encoded[0], dtype = np.float32)\n",
        "  z_encoded = np.subtract(z_encoded, min_1)\n",
        "  z_encoded = np.divide(z_encoded, np.subtract(max_1, min_1))\n",
        "  z_encoded = np.multiply(z_encoded, np.subtract(max_2, min_2))\n",
        "  z_encoded = np.add(z_encoded, min_2)\n",
        "  return(decoder.predict(z_encoded))\n",
        "\n",
        "decoded_and_applied = apply_one_to_the_other(encoder, decoder, input_data_1, scale_min_1, scale_max_1, scale_min_2, scale_max_2)\n",
        "\n",
        "#x = range(0, 512)\n",
        "#import matplotlib.pyplot as plt\n",
        "#plt.plot(x,input_data_1[5000,])\n",
        "#plt.show()\n",
        "#x = range(0, 8192)\n",
        "#plt.plot(x,decoded_and_applied[5000,])\n",
        "#plt.show()\n",
        "\n",
        "mel_filter, mel_inversion_filter, window = initialize(fftsize, input_dim)\n",
        "output = np.zeros(decoded_and_applied.shape[0] * windowskip)\n",
        "sout = np.zeros((fftsize), dtype=np.float32)\n",
        "se = np.zeros(windowskip, dtype=np.float32)\n",
        "\n",
        "def callback(amp_frame, phase_frame, frame_size):\n",
        "    global sout\n",
        "\n",
        "    # DECODE\n",
        "    ca = np.zeros((1, int(fftsize / 2 + 1)), dtype=np.float32)\n",
        "    ca[0,0:int(fftsize/2)] = amp_frame\n",
        "    ca[0,0] = 0.\n",
        "\n",
        "    # GENERATE NOISE TO USE AS RECONSTRUCTION PHASE\n",
        "    ph = phase_frame\n",
        "\n",
        "    # CONVERT BACK TO A SIGNAL\n",
        "    co = np.zeros(int(fftsize / 2 + 1), dtype='complex64')\n",
        "    co.real[0:int(fftsize/2,)] = np.multiply(amp_frame, np.cos(phase_frame))\n",
        "    co.imag[0:int(fftsize/2,)]= np.multiply(amp_frame, np.sin(phase_frame))\n",
        "    cs = np.multiply(np.fft.irfft(co), window)\n",
        "\n",
        "    sout[0:(fftsize - frame_size)] = sout[frame_size:fftsize]\n",
        "    sout[(fftsize - frame_size):fftsize] = se\n",
        "    sout = np.add(sout, cs)[0,]\n",
        "    return(np.multiply(sout[0:frame_size].astype(np.float32), 1.))\n",
        "\n",
        "for i in range(0, decoded_and_applied.shape[0]):\n",
        "    output[i * windowskip:(i + 1) * windowskip] = callback(decoded_and_applied[i,], phase_data_1[i,], 1024)\n",
        "\n",
        "scipy.io.wavfile.write(filename_1 + \"-resynth.wav\", 44100, np.divide(output, np.amax(output)))\n"
      ],
      "metadata": {
        "id": "GjW5T2IqS-e8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSwU5HYYfk_a"
      },
      "source": [
        "<-- You can download the model as a zip filename.wav-resynth.wav from the file browser on the left."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "autoencoder_merge_test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}